% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gdrm_fitters.R
\name{gdrm_adam}
\alias{gdrm_adam}
\title{ADAM Optimization for gdrm models}
\usage{
gdrm_adam(
  response,
  distrib,
  mod_comp,
  map_functions,
  adam_control_list = adam_control()
)
}
\arguments{
\item{response}{Response variable.}

\item{distrib}{A \code{\link{distrib}} object.}

\item{mod_comp}{A list of model components from \verb{[interpret_formulae()]}.}

\item{map_functions}{A list of functions to map parameters from constrained to real line created by \code{\link[=make_map_function]{make_map_function()}}.}

\item{adam_control_list}{A list of options returned by \code{\link[=adam_control]{adam_control()}} function.}
}
\value{
A list with components:
\item{mod_comp}{Updated model components with optimized parameter values.}
\item{it}{Integer. Number of iterations until convergence.}
}
\description{
Fits generalized distributional regression models using the ADAM optimization
algorithm. This function optimizes model parameters by maximizing the
log-likelihood using adaptive moment estimation.
}
\details{
The function implements the ADAM optimization algorithm for maximum likelihood
estimation in generalized distributional regression models. ADAM maintains
separate adaptive learning rates for each parameter by computing exponential
moving averages of gradients and their squared values.

The algorithm updates parameters using bias-corrected moment estimates:
\deqn{m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t}
\deqn{v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2}
\deqn{\hat{m}_t = \frac{m_t}{1-\beta_1^t}}
\deqn{\hat{v}_t = \frac{v_t}{1-\beta_2^t}}
\deqn{\theta_{t+1} = \theta_t + \frac{\alpha \hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}}

Convergence is determined by either gradient tolerance, parameter change
tolerance, or both (depending on \code{require_both} setting).
}
\seealso{
\code{\link{adam_control}} for control parameter specification.
}
